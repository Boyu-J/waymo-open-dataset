{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Boyu-J/waymo-open-dataset/blob/master/Working_Waymo_Motion_Dataset_0416.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pVhOfzLx9us"
      },
      "source": [
        "#Waymo Open Dataset Tutorial\n",
        "\n",
        "- Website: https://waymo.com/open\n",
        "- GitHub: https://github.com/waymo-research/waymo-open-dataset\n",
        "\n",
        "This tutorial demonstrates how to use the Waymo Open Dataset with two frames of data. Visit the [Waymo Open Dataset Website](https://waymo.com/open) to download the full dataset.\n",
        "\n",
        "To use, open this notebook in [Colab](https://colab.research.google.com).\n",
        "\n",
        "Uncheck the box \"Reset all runtimes before running\" if you run this colab directly from the remote kernel. Alternatively, you can make a copy before trying to run it by following \"File > Save copy in Drive ...\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWdJUWiZdMte"
      },
      "source": [
        "## Install waymo_open_dataset package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxX_JIZrdKoR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65559d5d-8b4c-4db9-c48c-83f62474d471"
      },
      "source": [
        "!rm -rf waymo-od > /dev/null\n",
        "!git clone https://github.com/waymo-research/waymo-open-dataset.git waymo-od\n",
        "!cd waymo-od && git branch -a\n",
        "!cd waymo-od && git checkout remotes/origin/master\n",
        "!pip3 install --upgrade pip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'waymo-od'...\n",
            "remote: Enumerating objects: 2479, done.\u001b[K\n",
            "remote: Counting objects: 100% (2479/2479), done.\u001b[K\n",
            "remote: Compressing objects: 100% (707/707), done.\u001b[K\n",
            "remote: Total 2479 (delta 1767), reused 2424 (delta 1745), pack-reused 0\n",
            "Receiving objects: 100% (2479/2479), 86.05 MiB | 33.16 MiB/s, done.\n",
            "Resolving deltas: 100% (1767/1767), done.\n",
            "* \u001b[32mmaster\u001b[m\n",
            "  \u001b[31mremotes/origin/HEAD\u001b[m -> origin/master\n",
            "  \u001b[31mremotes/origin/master\u001b[m\n",
            "  \u001b[31mremotes/origin/om2\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.0\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.0-tf1.15\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.0-tf2.0\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.2\u001b[m\n",
            "  \u001b[31mremotes/origin/r1.3\u001b[m\n",
            "Note: switching to 'remotes/origin/master'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n",
            "HEAD is now at 1eabdda Merged commit includes the following changes: 523906316  by Waymo Research:\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (23.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-23.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.0.1\n",
            "    Uninstalling pip-23.0.1:\n",
            "      Successfully uninstalled pip-23.0.1\n",
            "Successfully installed pip-23.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sLIUOJzSyjj6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7944521-424d-456e-fbee-8c85fe33f8c0"
      },
      "source": [
        "!pip3 install waymo-open-dataset-tf-2-6-0"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting waymo-open-dataset-tf-2-6-0\n",
            "  Downloading waymo_open_dataset_tf_2_6_0-1.4.9-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow==2.6.0 (from waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading tensorflow-2.6.0-cp39-cp39-manylinux2010_x86_64.whl (458.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m458.4/458.4 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly>=5.5.0 in /usr/local/lib/python3.9/dist-packages (from waymo-open-dataset-tf-2-6-0) (5.13.1)\n",
            "Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from waymo-open-dataset-tf-2-6-0) (3.7.1)\n",
            "Requirement already satisfied: scikit-image>=0.17.2immutabledict>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from waymo-open-dataset-tf-2-6-0) (0.19.3)\n",
            "Collecting numpy~=1.19.2 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py~=0.10 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (1.6.3)\n",
            "Collecting clang~=5.0 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading clang-5.0.tar.gz (30 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting flatbuffers~=1.12.0 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (0.2.0)\n",
            "Collecting h5py~=3.1.0 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing~=1.1.2 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (3.20.3)\n",
            "Collecting six~=1.15.0 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting termcolor~=1.1.0 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting typing-extensions~=3.7.4 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (0.40.0)\n",
            "Collecting wrapt~=1.12.1 (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2.12.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (1.53.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->waymo-open-dataset-tf-2-6-0) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->waymo-open-dataset-tf-2-6-0) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->waymo-open-dataset-tf-2-6-0) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->waymo-open-dataset-tf-2-6-0) (1.4.4)\n",
            "INFO: pip is looking at multiple versions of matplotlib to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting matplotlib>=3.2.2 (from waymo-open-dataset-tf-2-6-0)\n",
            "  Downloading matplotlib-3.7.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading matplotlib-3.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->waymo-open-dataset-tf-2-6-0) (23.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->waymo-open-dataset-tf-2-6-0) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->waymo-open-dataset-tf-2-6-0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib>=3.2.2->waymo-open-dataset-tf-2-6-0) (2.8.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly>=5.5.0->waymo-open-dataset-tf-2-6-0) (8.2.2)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.17.2immutabledict>=2.0.0->waymo-open-dataset-tf-2-6-0) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.17.2immutabledict>=2.0.0->waymo-open-dataset-tf-2-6-0) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.17.2immutabledict>=2.0.0->waymo-open-dataset-tf-2-6-0) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.17.2immutabledict>=2.0.0->waymo-open-dataset-tf-2-6-0) (2023.3.21)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.17.2immutabledict>=2.0.0->waymo-open-dataset-tf-2-6-0) (1.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (67.6.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (6.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow==2.6.0->waymo-open-dataset-tf-2-6-0) (3.2.2)\n",
            "Building wheels for collected packages: clang, termcolor, wrapt\n",
            "  Building wheel for clang (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30692 sha256=f18f3bf28fd3dc7e606d7d622a1e6cef18c23700fe74beedbcd1b495d575e91a\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/ce/7a/27094f689461801c934296d07078773603663dfcaca63bb064\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4845 sha256=9734f0743125f53c453dac8e8f5477502006238bd118cfcc8b9337c1a073da3e\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=75947 sha256=ddf59a0a30155b92b48ba1c17594c21744ba8422332ab3370591e656826a1dea\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
            "Successfully built clang termcolor wrapt\n",
            "Installing collected packages: wrapt, typing-extensions, termcolor, flatbuffers, clang, six, numpy, keras-preprocessing, h5py, absl-py, matplotlib, tensorflow, waymo-open-dataset-tf-2-6-0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.14.1\n",
            "    Uninstalling wrapt-1.14.1:\n",
            "      Successfully uninstalled wrapt-1.14.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.2.0\n",
            "    Uninstalling termcolor-2.2.0:\n",
            "      Successfully uninstalled termcolor-2.2.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 23.3.3\n",
            "    Uninstalling flatbuffers-23.3.3:\n",
            "      Successfully uninstalled flatbuffers-23.3.3\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.22.4\n",
            "    Uninstalling numpy-1.22.4:\n",
            "      Successfully uninstalled numpy-1.22.4\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.8.0\n",
            "    Uninstalling h5py-3.8.0:\n",
            "      Successfully uninstalled h5py-3.8.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: matplotlib\n",
            "    Found existing installation: matplotlib 3.7.1\n",
            "    Uninstalling matplotlib-3.7.1:\n",
            "      Successfully uninstalled matplotlib-3.7.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.9 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "arviz 0.15.1 requires numpy>=1.20.0, but you have numpy 1.19.5 which is incompatible.\n",
            "arviz 0.15.1 requires typing-extensions>=4.1.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "astropy 5.2.2 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "bokeh 2.4.3 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "chex 0.1.7 requires typing-extensions>=4.2.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "cmdstanpy 1.1.0 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "flax 0.6.8 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "jax 0.4.8 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "jaxlib 0.4.7+cuda11.cudnn86 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "librosa 0.10.0.post2 requires numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3, but you have numpy 1.19.5 which is incompatible.\n",
            "librosa 0.10.0.post2 requires typing-extensions>=4.1.1, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "ml-dtypes 0.0.4 requires numpy>1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "optax 0.1.4 requires typing-extensions>=3.10.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "pandas 1.5.3 requires numpy>=1.20.3; python_version < \"3.10\", but you have numpy 1.19.5 which is incompatible.\n",
            "pydantic 1.10.7 requires typing-extensions>=4.2.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "xarray 2022.12.0 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\n",
            "xarray-einstats 0.5.1 requires numpy>=1.20, but you have numpy 1.19.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed absl-py-0.15.0 clang-5.0 flatbuffers-1.12 h5py-3.1.0 keras-preprocessing-1.1.2 matplotlib-3.6.3 numpy-1.19.5 six-1.15.0 tensorflow-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3 waymo-open-dataset-tf-2-6-0-1.4.9 wrapt-1.12.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDQ1DPqwdfNW"
      },
      "source": [
        "import os\n",
        "import tensorflow.compat.v1 as tf\n",
        "import math\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "from waymo_open_dataset.utils import range_image_utils\n",
        "from waymo_open_dataset.utils import transform_utils\n",
        "from waymo_open_dataset.utils import  frame_utils\n",
        "from waymo_open_dataset import dataset_pb2 as open_dataset"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibor0U9XBlX6"
      },
      "source": [
        "## Read one frame\n",
        "\n",
        "Each file in the dataset is a sequence of frames ordered by frame start timestamps. We have extracted two frames from the dataset to demonstrate the dataset format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29uZtYLJBx2r"
      },
      "source": [
        "FILENAME = '/content/waymo-od/tutorial/frames'\n",
        "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
        "for data in dataset:\n",
        "    frame = open_dataset.Frame()\n",
        "    frame.ParseFromString(bytearray(data.numpy()))\n",
        "    break"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHK95_JBUXUx"
      },
      "source": [
        "(range_images, camera_projections,\n",
        " _, range_image_top_pose) = frame_utils.parse_range_image_and_camera_projection(\n",
        "    frame)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eorb6V2qznV_"
      },
      "source": [
        "###Examine frame context\n",
        "\n",
        "Refer to [dataset.proto](https://github.com/waymo-research/waymo-open-dataset/blob/master/waymo_open_dataset/dataset.proto) for the data format. The context contains shared information among all frames in the scene."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZotEevt7S0fE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be56500-3993-4eec-e925-89005febbd8b"
      },
      "source": [
        "print(frame.context)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name: \"11004685739714500220_2300_000_2320_000\"\n",
            "camera_calibrations {\n",
            "  name: FRONT\n",
            "  intrinsic: 2055.556149361639\n",
            "  intrinsic: 2055.556149361639\n",
            "  intrinsic: 939.6574698861468\n",
            "  intrinsic: 641.0721821943271\n",
            "  intrinsic: 0.03231600849798887\n",
            "  intrinsic: -0.3214124825527059\n",
            "  intrinsic: 0.0007932583953709973\n",
            "  intrinsic: -0.0006257493541333847\n",
            "  intrinsic: 0.0\n",
            "  extrinsic {\n",
            "    transform: 0.9998926849887427\n",
            "    transform: -0.005993208400016058\n",
            "    transform: 0.0133678704017097\n",
            "    transform: 1.5389142447125008\n",
            "    transform: 0.006042236521329663\n",
            "    transform: 0.9999751560547995\n",
            "    transform: -0.003630241176497072\n",
            "    transform: -0.02363394083934774\n",
            "    transform: -0.013345781499156929\n",
            "    transform: 0.003710623431877962\n",
            "    transform: 0.999904056092345\n",
            "    transform: 2.115270572975561\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "  width: 1920\n",
            "  height: 1280\n",
            "  rolling_shutter_direction: LEFT_TO_RIGHT\n",
            "}\n",
            "camera_calibrations {\n",
            "  name: FRONT_LEFT\n",
            "  intrinsic: 2063.7008688972\n",
            "  intrinsic: 2063.7008688972\n",
            "  intrinsic: 970.7315379934879\n",
            "  intrinsic: 639.9082229848484\n",
            "  intrinsic: 0.03119623557580319\n",
            "  intrinsic: -0.34029064830905453\n",
            "  intrinsic: -0.0006801050887136624\n",
            "  intrinsic: 0.001067963528920262\n",
            "  intrinsic: 0.0\n",
            "  extrinsic {\n",
            "    transform: 0.7163508489464225\n",
            "    transform: -0.6976495294008019\n",
            "    transform: 0.011251459486630241\n",
            "    transform: 1.492930189258495\n",
            "    transform: 0.6976096514642995\n",
            "    transform: 0.7164356249377603\n",
            "    transform: 0.007795479709391459\n",
            "    transform: 0.09192224912318936\n",
            "    transform: -0.01349945915947628\n",
            "    transform: 0.0022648282231656253\n",
            "    transform: 0.9999063131891514\n",
            "    transform: 2.1152105284507554\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "  width: 1920\n",
            "  height: 1280\n",
            "  rolling_shutter_direction: LEFT_TO_RIGHT\n",
            "}\n",
            "camera_calibrations {\n",
            "  name: FRONT_RIGHT\n",
            "  intrinsic: 2056.0892196793116\n",
            "  intrinsic: 2056.0892196793116\n",
            "  intrinsic: 935.743715862858\n",
            "  intrinsic: 624.4064324983569\n",
            "  intrinsic: 0.03490672761153742\n",
            "  intrinsic: -0.3141180156718857\n",
            "  intrinsic: 0.0012619308568439455\n",
            "  intrinsic: -0.0026996059700096116\n",
            "  intrinsic: 0.0\n",
            "  extrinsic {\n",
            "    transform: 0.716582596758835\n",
            "    transform: 0.6975019454936628\n",
            "    transform: -0.000646571666883216\n",
            "    transform: 1.490324906589904\n",
            "    transform: -0.6974986018023605\n",
            "    transform: 0.71657554968999\n",
            "    transform: -0.0038964176163232226\n",
            "    transform: -0.09385927001229258\n",
            "    transform: -0.002254441420230414\n",
            "    transform: 0.003243087887177829\n",
            "    transform: 0.9999921999069986\n",
            "    transform: 2.1154927516413125\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "  width: 1920\n",
            "  height: 1280\n",
            "  rolling_shutter_direction: LEFT_TO_RIGHT\n",
            "}\n",
            "camera_calibrations {\n",
            "  name: SIDE_LEFT\n",
            "  intrinsic: 2066.834902319412\n",
            "  intrinsic: 2066.834902319412\n",
            "  intrinsic: 952.8608233319966\n",
            "  intrinsic: 249.49859488407833\n",
            "  intrinsic: 0.044941016139828975\n",
            "  intrinsic: -0.3435919955955713\n",
            "  intrinsic: 0.00013187735016933997\n",
            "  intrinsic: -0.0011427074991115992\n",
            "  intrinsic: 0.0\n",
            "  extrinsic {\n",
            "    transform: 0.0012964074354981448\n",
            "    transform: -0.9999536359093453\n",
            "    transform: 0.009541769198720481\n",
            "    transform: 1.4314958432756546\n",
            "    transform: 0.9997854749192748\n",
            "    transform: 0.0014933173193322094\n",
            "    transform: 0.020658512623705133\n",
            "    transform: 0.11128578863910166\n",
            "    transform: -0.020671803699754576\n",
            "    transform: 0.009512940400541162\n",
            "    transform: 0.9997410567225569\n",
            "    transform: 2.115330824237742\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "  width: 1920\n",
            "  height: 886\n",
            "  rolling_shutter_direction: LEFT_TO_RIGHT\n",
            "}\n",
            "camera_calibrations {\n",
            "  name: SIDE_RIGHT\n",
            "  intrinsic: 2054.797701053215\n",
            "  intrinsic: 2054.797701053215\n",
            "  intrinsic: 972.7435431831157\n",
            "  intrinsic: 242.4987260630087\n",
            "  intrinsic: 0.03337281654124105\n",
            "  intrinsic: -0.313299913027001\n",
            "  intrinsic: -0.0001886604822006906\n",
            "  intrinsic: -0.0012474351513059548\n",
            "  intrinsic: 0.0\n",
            "  extrinsic {\n",
            "    transform: -0.00192725729868321\n",
            "    transform: 0.9999977777956348\n",
            "    transform: -0.000854449001917361\n",
            "    transform: 1.428371747589099\n",
            "    transform: -0.9999943442124861\n",
            "    transform: -0.0019296044058050511\n",
            "    transform: -0.00275466329645372\n",
            "    transform: -0.11149205023810704\n",
            "    transform: -0.002756305923587554\n",
            "    transform: 0.0008491352243918596\n",
            "    transform: 0.9999958408648639\n",
            "    transform: 2.1156692490324467\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "  width: 1920\n",
            "  height: 886\n",
            "  rolling_shutter_direction: LEFT_TO_RIGHT\n",
            "}\n",
            "laser_calibrations {\n",
            "  name: FRONT\n",
            "  beam_inclination_min: -1.5707963267948966\n",
            "  beam_inclination_max: 0.5235987755982988\n",
            "  extrinsic {\n",
            "    transform: 0.9998652264631824\n",
            "    transform: -0.012374982714412487\n",
            "    transform: 0.01078836004899645\n",
            "    transform: 4.07\n",
            "    transform: 0.012370123575608356\n",
            "    transform: 0.9999233534288761\n",
            "    transform: 0.0005170205750618116\n",
            "    transform: 0.0\n",
            "    transform: -0.010793931278870031\n",
            "    transform: -0.0003834975473860608\n",
            "    transform: 0.9999416702874113\n",
            "    transform: 0.689\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "}\n",
            "laser_calibrations {\n",
            "  name: REAR\n",
            "  beam_inclination_min: -1.5707963267948966\n",
            "  beam_inclination_max: 0.5235987755982988\n",
            "  extrinsic {\n",
            "    transform: -0.9998203426768512\n",
            "    transform: -0.0012366249062338462\n",
            "    transform: -0.018914363018232017\n",
            "    transform: -1.155\n",
            "    transform: 0.0012444047907441676\n",
            "    transform: -0.9999991459049238\n",
            "    transform: -0.0003995574296983207\n",
            "    transform: 0.0\n",
            "    transform: -0.018913852760898655\n",
            "    transform: -0.0004230227702338191\n",
            "    transform: 0.999821027597177\n",
            "    transform: 0.464\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "}\n",
            "laser_calibrations {\n",
            "  name: SIDE_LEFT\n",
            "  beam_inclination_min: -1.5707963267948966\n",
            "  beam_inclination_max: 0.5235987755982988\n",
            "  extrinsic {\n",
            "    transform: 0.0031797778574763464\n",
            "    transform: -0.9999778127632065\n",
            "    transform: 0.005853460010174735\n",
            "    transform: 3.245\n",
            "    transform: 0.9997496883031569\n",
            "    transform: 0.003308576153464576\n",
            "    transform: 0.022127224443596244\n",
            "    transform: 1.025\n",
            "    transform: -0.022146100119832854\n",
            "    transform: 0.0057816351623340275\n",
            "    transform: 0.9997380271572809\n",
            "    transform: 0.979\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "}\n",
            "laser_calibrations {\n",
            "  name: SIDE_RIGHT\n",
            "  beam_inclination_min: -1.5707963267948966\n",
            "  beam_inclination_max: 0.5235987755982988\n",
            "  extrinsic {\n",
            "    transform: -0.006492366214414203\n",
            "    transform: 0.9999718528565993\n",
            "    transform: -0.0037606748700064157\n",
            "    transform: 3.245\n",
            "    transform: -0.9994155217525648\n",
            "    transform: -0.006614886675273215\n",
            "    transform: -0.03353890508531984\n",
            "    transform: -1.025\n",
            "    transform: -0.03356283749903654\n",
            "    transform: 0.003540729983104845\n",
            "    transform: 0.9994303373273197\n",
            "    transform: 0.979\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "}\n",
            "laser_calibrations {\n",
            "  name: TOP\n",
            "  beam_inclinations: -0.3096316354429449\n",
            "  beam_inclinations: -0.2990935195213844\n",
            "  beam_inclinations: -0.2885804618889636\n",
            "  beam_inclinations: -0.2780952907528751\n",
            "  beam_inclinations: -0.26770166528932315\n",
            "  beam_inclinations: -0.25860954459162877\n",
            "  beam_inclinations: -0.24891719273633606\n",
            "  beam_inclinations: -0.2398364216126483\n",
            "  beam_inclinations: -0.23026933024027318\n",
            "  beam_inclinations: -0.22129750913016077\n",
            "  beam_inclinations: -0.21174633688986222\n",
            "  beam_inclinations: -0.2032086979548664\n",
            "  beam_inclinations: -0.1947109529391673\n",
            "  beam_inclinations: -0.18654917552985428\n",
            "  beam_inclinations: -0.1777966336707011\n",
            "  beam_inclinations: -0.17010542288047326\n",
            "  beam_inclinations: -0.1619204344014964\n",
            "  beam_inclinations: -0.15447645249605046\n",
            "  beam_inclinations: -0.14694637475217442\n",
            "  beam_inclinations: -0.1397572897671926\n",
            "  beam_inclinations: -0.13224985399358657\n",
            "  beam_inclinations: -0.12515786941652007\n",
            "  beam_inclinations: -0.11819281200913823\n",
            "  beam_inclinations: -0.11179264288730995\n",
            "  beam_inclinations: -0.10511618389309652\n",
            "  beam_inclinations: -0.09898137927534933\n",
            "  beam_inclinations: -0.09276671098228917\n",
            "  beam_inclinations: -0.08680787309428584\n",
            "  beam_inclinations: -0.08079759055774005\n",
            "  beam_inclinations: -0.07560577852119499\n",
            "  beam_inclinations: -0.07014871723471439\n",
            "  beam_inclinations: -0.0657064593506993\n",
            "  beam_inclinations: -0.06044682633210763\n",
            "  beam_inclinations: -0.055976841503205366\n",
            "  beam_inclinations: -0.05128120535416136\n",
            "  beam_inclinations: -0.04749513726931931\n",
            "  beam_inclinations: -0.0432988365724023\n",
            "  beam_inclinations: -0.039475988511034954\n",
            "  beam_inclinations: -0.035508677900720764\n",
            "  beam_inclinations: -0.031933982130093685\n",
            "  beam_inclinations: -0.02871096926661365\n",
            "  beam_inclinations: -0.025798766187801636\n",
            "  beam_inclinations: -0.02271463019401887\n",
            "  beam_inclinations: -0.020121800366877496\n",
            "  beam_inclinations: -0.016948351911716175\n",
            "  beam_inclinations: -0.014038209415881964\n",
            "  beam_inclinations: -0.010949318393027596\n",
            "  beam_inclinations: -0.008391388807776234\n",
            "  beam_inclinations: -0.005178693738374873\n",
            "  beam_inclinations: -0.0025427113056801787\n",
            "  beam_inclinations: 0.0006093841244867448\n",
            "  beam_inclinations: 0.003502138844707181\n",
            "  beam_inclinations: 0.00647313242375791\n",
            "  beam_inclinations: 0.008942029457416067\n",
            "  beam_inclinations: 0.012146895773645028\n",
            "  beam_inclinations: 0.014853056290285105\n",
            "  beam_inclinations: 0.018218260030434363\n",
            "  beam_inclinations: 0.020994285647720767\n",
            "  beam_inclinations: 0.024042142492056495\n",
            "  beam_inclinations: 0.02667281252267184\n",
            "  beam_inclinations: 0.029578993878473625\n",
            "  beam_inclinations: 0.032332878595667136\n",
            "  beam_inclinations: 0.035812139673645715\n",
            "  beam_inclinations: 0.03858014672640575\n",
            "  beam_inclination_min: -0.3149006934037252\n",
            "  beam_inclination_max: 0.03996415025278577\n",
            "  extrinsic {\n",
            "    transform: -0.8501252893535083\n",
            "    transform: -0.5265748816393067\n",
            "    transform: 0.002426196233609717\n",
            "    transform: 1.43\n",
            "    transform: 0.5265789138981879\n",
            "    transform: -0.8501249566763436\n",
            "    transform: 0.0014850837854017132\n",
            "    transform: 0.0\n",
            "    transform: 0.0012805621494634083\n",
            "    transform: 0.002540091060376914\n",
            "    transform: 0.9999959540408083\n",
            "    transform: 2.184\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 0.0\n",
            "    transform: 1.0\n",
            "  }\n",
            "}\n",
            "stats {\n",
            "  laser_object_counts {\n",
            "    type: TYPE_VEHICLE\n",
            "    count: 13\n",
            "  }\n",
            "  laser_object_counts {\n",
            "    type: TYPE_PEDESTRIAN\n",
            "    count: 21\n",
            "  }\n",
            "  laser_object_counts {\n",
            "    type: TYPE_SIGN\n",
            "    count: 10\n",
            "  }\n",
            "  time_of_day: \"Day\"\n",
            "  location: \"location_sf\"\n",
            "  weather: \"sunny\"\n",
            "  camera_object_counts {\n",
            "    type: TYPE_VEHICLE\n",
            "    count: 9\n",
            "  }\n",
            "  camera_object_counts {\n",
            "    type: TYPE_PEDESTRIAN\n",
            "    count: 10\n",
            "  }\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YcpB9SHkW4v"
      },
      "source": [
        "## Visualize Camera Images and Camera Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18KfxT8RkMv0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "def show_camera_image(camera_image, camera_labels, layout, cmap=None):\n",
        "  \"\"\"Show a camera image and the given camera labels.\"\"\"\n",
        "\n",
        "  ax = plt.subplot(*layout)\n",
        "\n",
        "  # Draw the camera labels.\n",
        "  for camera_labels in frame.camera_labels:\n",
        "    # Ignore camera labels that do not correspond to this camera.\n",
        "    if camera_labels.name != camera_image.name:\n",
        "      continue\n",
        "\n",
        "    # Iterate over the individual labels.\n",
        "    for label in camera_labels.labels:\n",
        "      # Draw the object bounding box.\n",
        "      ax.add_patch(patches.Rectangle(\n",
        "        xy=(label.box.center_x - 0.5 * label.box.length,\n",
        "            label.box.center_y - 0.5 * label.box.width),\n",
        "        width=label.box.length,\n",
        "        height=label.box.width,\n",
        "        linewidth=1,\n",
        "        edgecolor='red',\n",
        "        facecolor='none'))\n",
        "\n",
        "  # Show the camera image.\n",
        "  plt.imshow(tf.image.decode_jpeg(camera_image.image), cmap=cmap)\n",
        "  plt.title(open_dataset.CameraName.Name.Name(camera_image.name))\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.figure(figsize=(25, 20))\n",
        "\n",
        "for index, image in enumerate(frame.images):\n",
        "  show_camera_image(image, frame.camera_labels, [3, 3, index+1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPc-xBE6VMHi"
      },
      "source": [
        "##Visualize Range Images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwZ4xcsHVO1V"
      },
      "source": [
        "plt.figure(figsize=(64, 20))\n",
        "def plot_range_image_helper(data, name, layout, vmin = 0, vmax=1, cmap='gray'):\n",
        "  \"\"\"Plots range image.\n",
        "\n",
        "  Args:\n",
        "    data: range image data\n",
        "    name: the image title\n",
        "    layout: plt layout\n",
        "    vmin: minimum value of the passed data\n",
        "    vmax: maximum value of the passed data\n",
        "    cmap: color map\n",
        "  \"\"\"\n",
        "  plt.subplot(*layout)\n",
        "  plt.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax)\n",
        "  plt.title(name)\n",
        "  plt.grid(False)\n",
        "  plt.axis('off')\n",
        "\n",
        "def get_range_image(laser_name, return_index):\n",
        "  \"\"\"Returns range image given a laser name and its return index.\"\"\"\n",
        "  return range_images[laser_name][return_index]\n",
        "\n",
        "def show_range_image(range_image, layout_index_start = 1):\n",
        "  \"\"\"Shows range image.\n",
        "\n",
        "  Args:\n",
        "    range_image: the range image data from a given lidar of type MatrixFloat.\n",
        "    layout_index_start: layout offset\n",
        "  \"\"\"\n",
        "  range_image_tensor = tf.convert_to_tensor(range_image.data)\n",
        "  range_image_tensor = tf.reshape(range_image_tensor, range_image.shape.dims)\n",
        "  lidar_image_mask = tf.greater_equal(range_image_tensor, 0)\n",
        "  range_image_tensor = tf.where(lidar_image_mask, range_image_tensor,\n",
        "                                tf.ones_like(range_image_tensor) * 1e10)\n",
        "  range_image_range = range_image_tensor[...,0] \n",
        "  range_image_intensity = range_image_tensor[...,1]\n",
        "  range_image_elongation = range_image_tensor[...,2]\n",
        "  plot_range_image_helper(range_image_range.numpy(), 'range',\n",
        "                   [8, 1, layout_index_start], vmax=75, cmap='gray')\n",
        "  plot_range_image_helper(range_image_intensity.numpy(), 'intensity',\n",
        "                   [8, 1, layout_index_start + 1], vmax=1.5, cmap='gray')\n",
        "  plot_range_image_helper(range_image_elongation.numpy(), 'elongation',\n",
        "                   [8, 1, layout_index_start + 2], vmax=1.5, cmap='gray')\n",
        "frame.lasers.sort(key=lambda laser: laser.name)\n",
        "show_range_image(get_range_image(open_dataset.LaserName.TOP, 0), 1)\n",
        "show_range_image(get_range_image(open_dataset.LaserName.TOP, 1), 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Lwd2nVpex7"
      },
      "source": [
        "##Point Cloud Conversion and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIEDW1pfpmd-"
      },
      "source": [
        "points, cp_points = frame_utils.convert_range_image_to_point_cloud(\n",
        "    frame,\n",
        "    range_images,\n",
        "    camera_projections,\n",
        "    range_image_top_pose)\n",
        "points_ri2, cp_points_ri2 = frame_utils.convert_range_image_to_point_cloud(\n",
        "    frame,\n",
        "    range_images,\n",
        "    camera_projections,\n",
        "    range_image_top_pose,\n",
        "    ri_index=1)\n",
        "\n",
        "# 3d points in vehicle frame.\n",
        "points_all = np.concatenate(points, axis=0)\n",
        "points_all_ri2 = np.concatenate(points_ri2, axis=0)\n",
        "# camera projection corresponding to each point.\n",
        "cp_points_all = np.concatenate(cp_points, axis=0)\n",
        "cp_points_all_ri2 = np.concatenate(cp_points_ri2, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MAKwTRWz3af"
      },
      "source": [
        "###Examine number of points in each lidar sensor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5_e4BCAGfYX"
      },
      "source": [
        "First return."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpsAJp2CqKrE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "96f279c8-b816-49a7-fed3-4383c3d798cc"
      },
      "source": [
        "print(points_all.shape)\n",
        "print(cp_points_all.shape)\n",
        "print(points_all[0:2])\n",
        "for i in range(5):\n",
        "  print(points[i].shape)\n",
        "  print(cp_points[i].shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-cc7a3bd5c07b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcp_points_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints_all\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'points_all' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n3cdlVYFGiE_"
      },
      "source": [
        "Second return."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QX6aj2EDGlRo"
      },
      "source": [
        "print(points_all_ri2.shape)\n",
        "print(cp_points_all_ri2.shape)\n",
        "print(points_all_ri2[0:2])\n",
        "for i in range(5):\n",
        "  print(points_ri2[i].shape)\n",
        "  print(cp_points_ri2[i].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCj3SDbuq9Nr"
      },
      "source": [
        "###Show point cloud\n",
        "3D point clouds are rendered using an internal tool, which is unfortunately not publicly available yet. Here is an example of what they look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K8VFnGnOq6cO"
      },
      "source": [
        "from IPython.display import Image, display\n",
        "display(Image('/content/waymo-od/tutorial/3d_point_cloud.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiGOSt4mr0xA"
      },
      "source": [
        "##Visualize Camera Projection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRMUN-hur9wO"
      },
      "source": [
        "images = sorted(frame.images, key=lambda i:i.name)\n",
        "cp_points_all_concat = np.concatenate([cp_points_all, points_all], axis=-1)\n",
        "cp_points_all_concat_tensor = tf.constant(cp_points_all_concat)\n",
        "\n",
        "# The distance between lidar points and vehicle frame origin.\n",
        "points_all_tensor = tf.norm(points_all, axis=-1, keepdims=True)\n",
        "cp_points_all_tensor = tf.constant(cp_points_all, dtype=tf.int32)\n",
        "\n",
        "mask = tf.equal(cp_points_all_tensor[..., 0], images[0].name)\n",
        "\n",
        "cp_points_all_tensor = tf.cast(tf.gather_nd(\n",
        "    cp_points_all_tensor, tf.where(mask)), dtype=tf.float32)\n",
        "points_all_tensor = tf.gather_nd(points_all_tensor, tf.where(mask))\n",
        "\n",
        "projected_points_all_from_raw_data = tf.concat(\n",
        "    [cp_points_all_tensor[..., 1:3], points_all_tensor], axis=-1).numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Invsxz0xsXNA"
      },
      "source": [
        "def rgba(r):\n",
        "  \"\"\"Generates a color based on range.\n",
        "\n",
        "  Args:\n",
        "    r: the range value of a given point.\n",
        "  Returns:\n",
        "    The color for a given range\n",
        "  \"\"\"\n",
        "  c = plt.get_cmap('jet')((r % 20.0) / 20.0)\n",
        "  c = list(c)\n",
        "  c[-1] = 0.5  # alpha\n",
        "  return c\n",
        "\n",
        "def plot_image(camera_image):\n",
        "  \"\"\"Plot a cmaera image.\"\"\"\n",
        "  plt.figure(figsize=(20, 12))\n",
        "  plt.imshow(tf.image.decode_jpeg(camera_image.image))\n",
        "  plt.grid(\"off\")\n",
        "\n",
        "def plot_points_on_image(projected_points, camera_image, rgba_func,\n",
        "                         point_size=5.0):\n",
        "  \"\"\"Plots points on a camera image.\n",
        "\n",
        "  Args:\n",
        "    projected_points: [N, 3] numpy array. The inner dims are\n",
        "      [camera_x, camera_y, range].\n",
        "    camera_image: jpeg encoded camera image.\n",
        "    rgba_func: a function that generates a color from a range value.\n",
        "    point_size: the point size.\n",
        "\n",
        "  \"\"\"\n",
        "  plot_image(camera_image)\n",
        "\n",
        "  xs = []\n",
        "  ys = []\n",
        "  colors = []\n",
        "\n",
        "  for point in projected_points:\n",
        "    xs.append(point[0])  # width, col\n",
        "    ys.append(point[1])  # height, row\n",
        "    colors.append(rgba_func(point[2]))\n",
        "\n",
        "  plt.scatter(xs, ys, c=colors, s=point_size, edgecolors=\"none\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx7mUQM2saI-"
      },
      "source": [
        "plot_points_on_image(projected_points_all_from_raw_data,\n",
        "                     images[0], rgba, point_size=5.0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rPeRqI54sBh"
      },
      "source": [
        "## Install from source code\n",
        "\n",
        "The remaining part of this colab covers details of installing the repo form source code which provides a richer API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8b-R3v1-6Eg"
      },
      "source": [
        "### Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhD5nAIV-5Hj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea8b5c4a-060e-4c60-ad12-2de7e57f3741"
      },
      "source": [
        "!sudo apt install build-essential\n",
        "!sudo apt-get install --assume-yes pkg-config zip g++ zlib1g-dev unzip python3 python3-pip\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/0.28.0/bazel-0.28.0-installer-linux-x86_64.sh\n",
        "!sudo bash ./bazel-0.28.0-installer-linux-x86_64.sh"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "build-essential is already the newest version (12.8ubuntu1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:9.3.0-1ubuntu2).\n",
            "g++ set to manually installed.\n",
            "pkg-config is already the newest version (0.29.1-0ubuntu4).\n",
            "python3 is already the newest version (3.8.2-0ubuntu2).\n",
            "python3 set to manually installed.\n",
            "zip is already the newest version (3.0-11build1).\n",
            "unzip is already the newest version (6.0-25ubuntu1.1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-2ubuntu1.5).\n",
            "zlib1g-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  python-pip-whl python3-setuptools python3-wheel\n",
            "Suggested packages:\n",
            "  python-setuptools-doc\n",
            "The following NEW packages will be installed:\n",
            "  python-pip-whl python3-pip python3-setuptools python3-wheel\n",
            "0 upgraded, 4 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 2,389 kB of archives.\n",
            "After this operation, 4,933 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python-pip-whl all 20.0.2-5ubuntu1.8 [1,805 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 python3-setuptools all 45.2.0-1ubuntu0.1 [330 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-wheel all 0.34.2-1ubuntu0.1 [23.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 python3-pip all 20.0.2-5ubuntu1.8 [231 kB]\n",
            "Fetched 2,389 kB in 1s (1,610 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package python-pip-whl.\n",
            "(Reading database ... 122349 files and directories currently installed.)\n",
            "Preparing to unpack .../python-pip-whl_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Selecting previously unselected package python3-setuptools.\n",
            "Preparing to unpack .../python3-setuptools_45.2.0-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-wheel.\n",
            "Preparing to unpack .../python3-wheel_0.34.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package python3-pip.\n",
            "Preparing to unpack .../python3-pip_20.0.2-5ubuntu1.8_all.deb ...\n",
            "Unpacking python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-setuptools (45.2.0-1ubuntu0.1) ...\n",
            "Setting up python3-wheel (0.34.2-1ubuntu0.1) ...\n",
            "Setting up python-pip-whl (20.0.2-5ubuntu1.8) ...\n",
            "Setting up python3-pip (20.0.2-5ubuntu1.8) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "--2023-04-16 20:36:41--  https://github.com/bazelbuild/bazel/releases/download/0.28.0/bazel-0.28.0-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/20773773/88363880-a340-11e9-8c2a-6eaee5a02203?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230416T203641Z&X-Amz-Expires=300&X-Amz-Signature=adaa866c1051a9ff1af7882026676bb08e8da4c505018dd0db020bbdb912a343&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-0.28.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2023-04-16 20:36:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/20773773/88363880-a340-11e9-8c2a-6eaee5a02203?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20230416%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20230416T203641Z&X-Amz-Expires=300&X-Amz-Signature=adaa866c1051a9ff1af7882026676bb08e8da4c505018dd0db020bbdb912a343&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-0.28.0-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 43701151 (42M) [application/octet-stream]\n",
            "Saving to: ‘bazel-0.28.0-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-0.28.0-instal 100%[===================>]  41.68M  44.3MB/s    in 0.9s    \n",
            "\n",
            "2023-04-16 20:36:42 (44.3 MB/s) - ‘bazel-0.28.0-installer-linux-x86_64.sh’ saved [43701151/43701151]\n",
            "\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# Release 0.28.0 (2019-07-10)\n",
            "\n",
            "Baseline: 2e374a9c6e3d4ed71f0145de287c4b2fe43c76d6\n",
            "\n",
            "Cherry picks:\n",
            "\n",
            "   + 6d0b14b95a71175362030b4811ca74512b00a890:\n",
            "     rule_test: apply \"tags\" to all rules in the macro\n",
            "\n",
            "Incompatible changes:\n",
            "\n",
            "  - Add --incompatible_enable_profile_by_default to enable the JSON\n",
            "    profile by default.\n",
            "  - The --incompatible_windows_style_arg_escaping flag is flipped to\n",
            "    \"true\", and the \"false\" case unsupported. Bazel no longer accepts\n",
            "    this flag.\n",
            "\n",
            "Important changes:\n",
            "\n",
            "  - Bazel now supports hiding compiler warnings for targets that\n",
            "    you're not explicitly building (see\n",
            "    https://docs.bazel.build/versions/master/user-manual.html#flag--au\n",
            "    to_output_filter).\n",
            "  - Flag `--incompatible_restrict_escape_sequences` is added. See\n",
            "    https://github.com/bazelbuild/bazel/issues/8380\n",
            "  - The \"info\" command now supports the \"starlark-semantics\"\n",
            "    argument, which outputs a representation of the effective Starlark\n",
            "    semantics option values.\n",
            "  - The `outputs` parameter of the `rule()` function is deprecated\n",
            "    and attached to flag `--incompatible_no_rule_outputs_param`.\n",
            "    Migrate rules to use `OutputGroupInfo` or `attr.output` instead.\n",
            "    See https://github.com/bazelbuild/bazel/issues/7977 for more info.\n",
            "  - When `--incompatible_strict_action_env` is enabled, the default\n",
            "    `PATH` now includes `/usr/local/bin`.\n",
            "  - Turn on --experimental_build_setting_api by default for starlark\n",
            "    build settings (see\n",
            "    https://docs.bazel.build/versions/master/skylark/config.html#user-\n",
            "    defined-build-settings for more info)\n",
            "  - `@bazel_tools//tools/jdk:toolchain_java10` and\n",
            "    `@bazel_tools//tools/jdk:toolchain_java11` are now available to\n",
            "    enable java 10, respectively java 11 language level support.\n",
            "  - The `command` parameter of the `actions.run_shell()` function\n",
            "    will be restricted to only accept strings (and not string\n",
            "    sequences). This check is attached to flag\n",
            "    `--incompatible_run_shell_command_string`. One may migrate by\n",
            "    using the `arguments` parameter of `actions.run()` instead. See\n",
            "    https://github.com/bazelbuild/bazel/issues/5903 for more info.\n",
            "  - Incompatible change\n",
            "    `--incompatible_use_platforms_repo_for_constraints` has been\n",
            "    added. See https://github.com/bazelbuild/bazel/issues/8622 for\n",
            "    details.\n",
            "  - Incompatible change\n",
            "    `--incompatible_use_platforms_repo_for_constraints` has been\n",
            "    added. See https://github.com/bazelbuild/bazel/issues/8622 f...\n",
            "  - Bazel's C++ autoconfiguration now understands `BAZEL_LINKLIBS`\n",
            "    environment variable to specify system libraries that should be\n",
            "    appended to the link command line.\n",
            "  - paths under the execution root starting with \".\" or \"_\" will be\n",
            "    re-linked across builds\n",
            "  - execution_log_json_file now allows actions without outputs.\n",
            "  - Labels aapt as deprecated for aapt_version, and heavily endorses\n",
            "    aapt2.\n",
            "  - Update doc links still pointing to cc_binary.features to point to\n",
            "    common features\n",
            "  - Incompatible change\n",
            "    `--incompatible_use_platforms_repo_for_constraints` has been\n",
            "    added. See https://github.com/bazelbuild/bazel/issues/8622 for\n",
            "    details.\n",
            "    RELNOTES:\n",
            "  - --incompatible_disable_nocopts flag has been added. See\n",
            "    https://github.com/bazelbuild/bazel/issues/8706 for details.\n",
            "  - Fixed treatment of <dist:module /> tags in AndroidManifest.xml\n",
            "  - Fixed asset precedence for android_binary rules with aapt2.\n",
            "  - Bazel now officially supports running on CentOS 7.\n",
            "  - The runtime dynamic libraries are no longer in default output\n",
            "    group of cc_binary.\n",
            "  - set the FDOBuildType as CSFDO for binaries built with\n",
            "    --cs_fdo_absolute_path.\n",
            "  - Bazel can now be bootstrapped and built on arm64 platforms\n",
            "    without requiring any flags or patches.\n",
            "  - Fixed treatment of AndroidManifest.xml attributes which contained\n",
            "    XML escaping\n",
            "  - Retire experimental blaze flag\n",
            "    experimental_link_compile_output_separately. The same behavior is\n",
            "    available through the feature dynamic_link_test_srcs.\n",
            "  - --incompatible_load_java_rules_from_bzl was added to forbid\n",
            "    loading the native java rules directly. See more on tracking\n",
            "    issue #8746\n",
            "  - Turn on --experimental_build_setting_api by default for starlark\n",
            "    build settings (see\n",
            "    https://docs.bazel.build/versions/master/skylark/config.html#user-\n",
            "    defined-build-settings for more info)\n",
            "  - Attribute names are going to be restricted and must be\n",
            "    syntactically valid identifiers.\n",
            "    https://github.com/bazelbuild/bazel/issues/6437\n",
            "  - rule_test: fix Bazel 0.27 regression (\"tags\" attribute was\n",
            "    ingored, https://github.com/bazelbuild/bazel/issues/8723\n",
            "\n",
            "This release contains contributions from many people at Google, as well as Ben Diuguid, Benjamin Peterson, Dave Lee, Loo Rong Jie, Mark Butcher, Marwan Tammam, Pedro Alvarez.\n",
            "\n",
            "## Build information\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/18cd904)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/usr/local/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /usr/local/lib/bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etZQJlyu_N-_"
      },
      "source": [
        "###Build and test (this can take 10 mins)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJmk8o-S_Flm"
      },
      "source": [
        "Configure .bazelrc. This works with/without Tensorflow. This colab machine has Tensorflow installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KscXNRZo_Rtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5912f04a-1a42-4fbb-bb55-2a4eddf15c36"
      },
      "source": [
        "!cd waymo-od && ./configure.sh && cat .bazelrc && bazel clean"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: ./configure.sh: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56xb_Ckj_8ZL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38514de7-28cd-416a-fd74-5f60518bebeb"
      },
      "source": [
        "!cd waymo-od && bazel build ... --show_progress_rate_limit=10.0"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting Bazel installation...\n",
            "ERROR: The 'build' command is only supported from within a workspace (below a directory having a WORKSPACE file).\n",
            "See documentation at https://docs.bazel.build/versions/master/build-ref.html#workspace\n",
            "WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8pO1b1EALPA"
      },
      "source": [
        "### Metrics computation\n",
        "The core metrics computation library is written in C++, so it can be extended to other programming languages. It can compute detection metrics (mAP) and tracking metrics (MOTA). See more information about the metrics on the [website](https://waymo.com/open/next/).\n",
        "\n",
        "We provide command line tools and TensorFlow ops to call the detection metrics library to compute detection metrics. We will provide a similar wrapper for tracking metrics library in the future. You are welcome to contribute your wrappers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIBufmNJBdGR"
      },
      "source": [
        "#### Command line detection metrics computation\n",
        "\n",
        "The command takes a pair of files for prediction and ground truth. Read the comment in waymo_open_dataset/metrics/tools/compute_detection_metrics_main.cc for details of the data format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDGzTcNgBVG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdc1b8bc-873b-4dd7-a29d-b481217f5ceb"
      },
      "source": [
        "!cd waymo-od && bazel-bin/waymo_open_dataset/metrics/tools/compute_detection_metrics_main waymo_open_dataset/metrics/tools/fake_predictions.bin  waymo_open_dataset/metrics/tools/fake_ground_truths.bin"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: bazel-bin/waymo_open_dataset/metrics/tools/compute_detection_metrics_main: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJn7Z9AjBii-"
      },
      "source": [
        "#### TensorFlow custom op\n",
        "\n",
        "A TensorFlow op is defined at metrics/ops/metrics_ops.cc. We provide a python wrapper of the op at metrics/ops/py_metrics_ops.py, and a tf.metrics-like implementation of the op at metrics/python/detection_metrics.py. This library requires TensorFlow to be installed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WB_BdDAYCQ62"
      },
      "source": [
        "Install TensorFlow and NumPy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXQqouc9CVWe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a3a2b67-e155-4325-fdc5-95bcc8ae7d9c"
      },
      "source": [
        "!pip3 install numpy tensorflow"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (1.19.5)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.9/dist-packages (2.6.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.15.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (5.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.12)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (3.7.4.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.40.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (0.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (2.12.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow) (1.53.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow) (2.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow) (2.27.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow) (67.6.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard~=2.6->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow) (6.3.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.6->tensorflow) (2.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.6->tensorflow) (3.15.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.6->tensorflow) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AURmNltwCYFx"
      },
      "source": [
        "Reconfigure .bazelrc such that you can compile the TensorFlow ops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jr2qkwYChDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f7e48b3-e90e-402f-f69e-613cbb613fe8"
      },
      "source": [
        "!cd waymo-od && ./configure.sh && cat .bazelrc"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: ./configure.sh: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkVOvmP4EOmD"
      },
      "source": [
        "Run the op and tf.metrics wrapper unit tests which can be referenced as example usage of the libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ArMxYB1E9j-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fab56f3a-a387-49f2-fc2e-177c77951b32"
      },
      "source": [
        "!cd waymo-od && bazel test waymo_open_dataset/metrics/ops/... && bazel test waymo_open_dataset/metrics/python/..."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: The 'test' command is only supported from within a workspace (below a directory having a WORKSPACE file).\n",
            "See documentation at https://docs.bazel.build/versions/master/build-ref.html#workspace\n",
            "WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "923OIUNSFCFw"
      },
      "source": [
        "Run all tests in the repo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytEO4tE3FHKo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f29d5d3-c3ea-4c51-c04b-c95db3c8ba02"
      },
      "source": [
        "!cd waymo-od && bazel test ..."
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ERROR: The 'test' command is only supported from within a workspace (below a directory having a WORKSPACE file).\n",
            "See documentation at https://docs.bazel.build/versions/master/build-ref.html#workspace\n",
            "WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_FpcGDRnAElo"
      },
      "source": [
        "### Build local PIP package"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwnPUOgVAHec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d004c086-5385-4a2e-a18b-872224edab39"
      },
      "source": [
        "!cd waymo-od && export PYTHON_VERSION=3 && ./pip_pkg_scripts/build.sh"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: ./pip_pkg_scripts/build.sh: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWcqyWarUbCv"
      },
      "source": [
        "You can install the locally compiled package or access any c++ binary compiled from this."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import os\n",
        "import uuid\n",
        "import time\n",
        "\n",
        "from matplotlib import cm\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.protobuf import text_format\n",
        "from waymo_open_dataset.metrics.ops import py_metrics_ops\n",
        "from waymo_open_dataset.metrics.python import config_util_py as config_util\n",
        "from waymo_open_dataset.protos import motion_metrics_pb2\n",
        "\n",
        "# Example field definition, change 20000 to 30000\n",
        "roadgraph_features = {\n",
        "    'roadgraph_samples/dir':\n",
        "        tf.io.FixedLenFeature([30000, 3], tf.float32, default_value=None),\n",
        "    'roadgraph_samples/id':\n",
        "        tf.io.FixedLenFeature([30000, 1], tf.int64, default_value=None),\n",
        "    'roadgraph_samples/type':\n",
        "        tf.io.FixedLenFeature([30000, 1], tf.int64, default_value=None),\n",
        "    'roadgraph_samples/valid':\n",
        "        tf.io.FixedLenFeature([30000, 1], tf.int64, default_value=None),\n",
        "    'roadgraph_samples/xyz':\n",
        "        tf.io.FixedLenFeature([30000, 3], tf.float32, default_value=None),\n",
        "}\n",
        "\n",
        "# Features of other agents.\n",
        "state_features = {\n",
        "    'state/id':\n",
        "        tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
        "    'state/type':\n",
        "        tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
        "    'state/is_sdc':\n",
        "        tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
        "    'state/tracks_to_predict':\n",
        "        tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
        "    'state/current/bbox_yaw':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/height':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/length':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/timestamp_micros':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
        "    'state/current/valid':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
        "    'state/current/vel_yaw':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/velocity_x':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/velocity_y':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/width':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/x':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/y':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/z':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/future/bbox_yaw':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/height':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/length':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/timestamp_micros':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
        "    'state/future/valid':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
        "    'state/future/vel_yaw':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/velocity_x':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/velocity_y':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/width':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/x':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/y':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/z':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/past/bbox_yaw':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/height':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/length':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/timestamp_micros':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
        "    'state/past/valid':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
        "    'state/past/vel_yaw':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/velocity_x':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/velocity_y':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/width':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/x':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/y':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/z':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "}\n",
        "\n",
        "traffic_light_features = {\n",
        "    'traffic_light_state/current/state':\n",
        "        tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
        "    'traffic_light_state/current/valid':\n",
        "        tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
        "    'traffic_light_state/current/x':\n",
        "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
        "    'traffic_light_state/current/y':\n",
        "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
        "    'traffic_light_state/current/z':\n",
        "        tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
        "    'traffic_light_state/past/state':\n",
        "        tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
        "    'traffic_light_state/past/valid':\n",
        "        tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
        "    'traffic_light_state/past/x':\n",
        "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
        "    'traffic_light_state/past/y':\n",
        "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
        "    'traffic_light_state/past/z':\n",
        "        tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
        "}\n",
        "\n",
        "features_description = {}\n",
        "features_description.update(roadgraph_features)\n",
        "features_description.update(state_features)\n",
        "features_description.update(traffic_light_features)"
      ],
      "metadata": {
        "id": "SIbW_sA1uHlD"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data location. Please edit.\n",
        "\n",
        "# A tfrecord containing tf.Example protos as downloaded from the Waymo dataset\n",
        "# webpage.\n",
        "\n",
        "# Replace this path with your own tfrecords.\n",
        "\n",
        "FILENAME = '/content/uncompressed_tf_example_training_training_tfexample.tfrecord-00012-of-01000'"
      ],
      "metadata": {
        "id": "P80XyJy8tts4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
        "data = next(dataset.as_numpy_iterator())\n",
        "parsed = tf.io.parse_single_example(data, features_description)"
      ],
      "metadata": {
        "id": "ehS6RvILuLPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(parsed))\n",
        "print(parsed.items())"
      ],
      "metadata": {
        "id": "TIk_IRNo3oQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data as json"
      ],
      "metadata": {
        "id": "qnbSYSBl3WFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# convert any non-serializable data types to a serializable data type\n",
        "for key, value in parsed.items():\n",
        "    if isinstance(value, tf.Tensor):\n",
        "        parsed[key] = value.numpy().tolist()\n",
        "\n",
        "# dump the modified dictionary to a JSON file\n",
        "with open('/content/training.json', 'w') as f:\n",
        "    json.dump(parsed, f)"
      ],
      "metadata": {
        "id": "kF4_LlSN3kIN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Plot the parsed data"
      ],
      "metadata": {
        "id": "ssjy_9aq4YEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_figure_and_axes(size_pixels):\n",
        "  \"\"\"Initializes a unique figure and axes for plotting.\"\"\"\n",
        "  fig, ax = plt.subplots(1, 1, num=uuid.uuid4())\n",
        "\n",
        "  # Sets output image to pixel resolution.\n",
        "  dpi = 100\n",
        "  size_inches = size_pixels / dpi\n",
        "  fig.set_size_inches([size_inches, size_inches])\n",
        "  fig.set_dpi(dpi)\n",
        "  fig.set_facecolor('white')\n",
        "  ax.set_facecolor('white')\n",
        "  ax.xaxis.label.set_color('black')\n",
        "  ax.tick_params(axis='x', colors='black')\n",
        "  ax.yaxis.label.set_color('black')\n",
        "  ax.tick_params(axis='y', colors='black')\n",
        "  fig.set_tight_layout(True)\n",
        "  ax.grid(False)\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "def fig_canvas_image(fig):\n",
        "  \"\"\"Returns a [H, W, 3] uint8 np.array image from fig.canvas.tostring_rgb().\"\"\"\n",
        "  # Just enough margin in the figure to display xticks and yticks.\n",
        "  fig.subplots_adjust(\n",
        "      left=0.08, bottom=0.08, right=0.98, top=0.98, wspace=0.0, hspace=0.0)\n",
        "  fig.canvas.draw()\n",
        "  data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8)\n",
        "  return data.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n",
        "\n",
        "\n",
        "def get_colormap(num_agents):\n",
        "  \"\"\"Compute a color map array of shape [num_agents, 4].\"\"\"\n",
        "  colors = cm.get_cmap('jet', num_agents)\n",
        "  colors = colors(range(num_agents))\n",
        "  np.random.shuffle(colors)\n",
        "  return colors\n",
        "\n",
        "\n",
        "def get_viewport(all_states, all_states_mask):\n",
        "  \"\"\"Gets the region containing the data.\n",
        "\n",
        "  Args:\n",
        "    all_states: states of agents as an array of shape [num_agents, num_steps,\n",
        "      2].\n",
        "    all_states_mask: binary mask of shape [num_agents, num_steps] for\n",
        "      `all_states`.\n",
        "\n",
        "  Returns:\n",
        "    center_y: float. y coordinate for center of data.\n",
        "    center_x: float. x coordinate for center of data.\n",
        "    width: float. Width of data.\n",
        "  \"\"\"\n",
        "  valid_states = all_states[all_states_mask]\n",
        "  all_y = valid_states[..., 1]\n",
        "  all_x = valid_states[..., 0]\n",
        "\n",
        "  center_y = (np.max(all_y) + np.min(all_y)) / 2\n",
        "  center_x = (np.max(all_x) + np.min(all_x)) / 2\n",
        "\n",
        "  range_y = np.ptp(all_y)\n",
        "  range_x = np.ptp(all_x)\n",
        "\n",
        "  width = max(range_y, range_x)\n",
        "\n",
        "  return center_y, center_x, width\n",
        "\n",
        "\n",
        "def visualize_one_step(states,\n",
        "                       mask,\n",
        "                       roadgraph,\n",
        "                       title,\n",
        "                       center_y,\n",
        "                       center_x,\n",
        "                       width,\n",
        "                       color_map,\n",
        "                       size_pixels=1000):\n",
        "  \"\"\"Generate visualization for a single step.\"\"\"\n",
        "\n",
        "  # Create figure and axes.\n",
        "  fig, ax = create_figure_and_axes(size_pixels=size_pixels)\n",
        "\n",
        "  # Plot roadgraph.\n",
        "  rg_pts = roadgraph[:, :2].T\n",
        "  ax.plot(rg_pts[0, :], rg_pts[1, :], 'k.', alpha=1, ms=2)\n",
        "\n",
        "  masked_x = states[:, 0][mask]\n",
        "  masked_y = states[:, 1][mask]\n",
        "  colors = color_map[mask]\n",
        "\n",
        "  # Plot agent current position.\n",
        "  ax.scatter(\n",
        "      masked_x,\n",
        "      masked_y,\n",
        "      marker='o',\n",
        "      linewidths=3,\n",
        "      color=colors,\n",
        "  )\n",
        "\n",
        "  # Title.\n",
        "  ax.set_title(title)\n",
        "\n",
        "  # Set axes.  Should be at least 10m on a side and cover 160% of agents.\n",
        "  size = max(10, width * 1.0)\n",
        "  ax.axis([\n",
        "      -size / 2 + center_x, size / 2 + center_x, -size / 2 + center_y,\n",
        "      size / 2 + center_y\n",
        "  ])\n",
        "  ax.set_aspect('equal')\n",
        "\n",
        "  image = fig_canvas_image(fig)\n",
        "  plt.close(fig)\n",
        "  return image\n",
        "\n",
        "\n",
        "def visualize_all_agents_smooth(\n",
        "    decoded_example,\n",
        "    size_pixels=1000,\n",
        "):\n",
        "  \"\"\"Visualizes all agent predicted trajectories in a serie of images.\n",
        "\n",
        "  Args:\n",
        "    decoded_example: Dictionary containing agent info about all modeled agents.\n",
        "    size_pixels: The size in pixels of the output image.\n",
        "\n",
        "  Returns:\n",
        "    T of [H, W, 3] uint8 np.arrays of the drawn matplotlib's figure canvas.\n",
        "  \"\"\"\n",
        "  # [num_agents, num_past_steps, 2] float32.\n",
        "  past_states = tf.stack(\n",
        "      [decoded_example['state/past/x'], decoded_example['state/past/y']],\n",
        "      -1).numpy()\n",
        "  past_states_mask = decoded_example['state/past/valid'].numpy() > 0.0\n",
        "\n",
        "  # [num_agents, 1, 2] float32.\n",
        "  current_states = tf.stack(\n",
        "      [decoded_example['state/current/x'], decoded_example['state/current/y']],\n",
        "      -1).numpy()\n",
        "  current_states_mask = decoded_example['state/current/valid'].numpy() > 0.0\n",
        "\n",
        "  # [num_agents, num_future_steps, 2] float32.\n",
        "  future_states = tf.stack(\n",
        "      [decoded_example['state/future/x'], decoded_example['state/future/y']],\n",
        "      -1).numpy()\n",
        "  future_states_mask = decoded_example['state/future/valid'].numpy() > 0.0\n",
        "\n",
        "  # [num_points, 3] float32.\n",
        "  roadgraph_xyz = decoded_example['roadgraph_samples/xyz'].numpy()\n",
        "\n",
        "  num_agents, num_past_steps, _ = past_states.shape\n",
        "  num_future_steps = future_states.shape[1]\n",
        "\n",
        "  color_map = get_colormap(num_agents)\n",
        "\n",
        "  # [num_agens, num_past_steps + 1 + num_future_steps, depth] float32.\n",
        "  all_states = np.concatenate([past_states, current_states, future_states], 1)\n",
        "\n",
        "  # [num_agens, num_past_steps + 1 + num_future_steps] float32.\n",
        "  all_states_mask = np.concatenate(\n",
        "      [past_states_mask, current_states_mask, future_states_mask], 1)\n",
        "\n",
        "  center_y, center_x, width = get_viewport(all_states, all_states_mask)\n",
        "\n",
        "  images = []\n",
        "\n",
        "  # Generate images from past time steps.\n",
        "  for i, (s, m) in enumerate(\n",
        "      zip(\n",
        "          np.split(past_states, num_past_steps, 1),\n",
        "          np.split(past_states_mask, num_past_steps, 1))):\n",
        "    im = visualize_one_step(s[:, 0], m[:, 0], roadgraph_xyz,\n",
        "                            'past: %d' % (num_past_steps - i), center_y,\n",
        "                            center_x, width, color_map, size_pixels)\n",
        "    images.append(im)\n",
        "\n",
        "  # Generate one image for the current time step.\n",
        "  s = current_states\n",
        "  m = current_states_mask\n",
        "\n",
        "  im = visualize_one_step(s[:, 0], m[:, 0], roadgraph_xyz, 'current', center_y,\n",
        "                          center_x, width, color_map, size_pixels)\n",
        "  images.append(im)\n",
        "\n",
        "  # Generate images from future time steps.\n",
        "  for i, (s, m) in enumerate(\n",
        "      zip(\n",
        "          np.split(future_states, num_future_steps, 1),\n",
        "          np.split(future_states_mask, num_future_steps, 1))):\n",
        "    im = visualize_one_step(s[:, 0], m[:, 0], roadgraph_xyz,\n",
        "                            'future: %d' % (i + 1), center_y, center_x, width,\n",
        "                            color_map, size_pixels)\n",
        "    images.append(im)\n",
        "\n",
        "  return images\n",
        "\n",
        "\n",
        "images = visualize_all_agents_smooth(parsed)"
      ],
      "metadata": {
        "id": "ZDEaN7tI4SZW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_animation(images):\n",
        "  \"\"\" Creates a Matplotlib animation of the given images.\n",
        "\n",
        "  Args:\n",
        "    images: A list of numpy arrays representing the images.\n",
        "\n",
        "  Returns:\n",
        "    A matplotlib.animation.Animation.\n",
        "\n",
        "  Usage:\n",
        "    anim = create_animation(images)\n",
        "    anim.save('/tmp/animation.avi')\n",
        "    HTML(anim.to_html5_video())\n",
        "  \"\"\"\n",
        "\n",
        "  plt.ioff()\n",
        "  fig, ax = plt.subplots()\n",
        "  dpi = 100\n",
        "  size_inches = 1000 / dpi\n",
        "  fig.set_size_inches([size_inches, size_inches])\n",
        "  plt.ion()\n",
        "\n",
        "  def animate_func(i):\n",
        "    ax.imshow(images[i])\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.grid('off')\n",
        "\n",
        "  anim = animation.FuncAnimation(\n",
        "      fig, animate_func, frames=len(images) // 2, interval=100)\n",
        "  plt.close(fig)\n",
        "  return anim\n",
        "\n",
        "\n",
        "anim = create_animation(images[::5])\n",
        "HTML(anim.to_html5_video())"
      ],
      "metadata": {
        "id": "OCUBF-hf4gYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.8"
      ],
      "metadata": {
        "id": "uehNXHJD50CI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _parse(value):\n",
        "  decoded_example = tf.io.parse_single_example(value, features_description)\n",
        "\n",
        "  past_states = tf.stack([\n",
        "      decoded_example['state/past/x'], decoded_example['state/past/y'],\n",
        "      decoded_example['state/past/length'], decoded_example['state/past/width'],\n",
        "      decoded_example['state/past/bbox_yaw'],\n",
        "      decoded_example['state/past/velocity_x'],\n",
        "      decoded_example['state/past/velocity_y']\n",
        "  ], -1)\n",
        "\n",
        "  cur_states = tf.stack([\n",
        "      decoded_example['state/current/x'], decoded_example['state/current/y'],\n",
        "      decoded_example['state/current/length'],\n",
        "      decoded_example['state/current/width'],\n",
        "      decoded_example['state/current/bbox_yaw'],\n",
        "      decoded_example['state/current/velocity_x'],\n",
        "      decoded_example['state/current/velocity_y']\n",
        "  ], -1)\n",
        "\n",
        "  input_states = tf.concat([past_states, cur_states], 1)[..., :2]\n",
        "\n",
        "  future_states = tf.stack([\n",
        "      decoded_example['state/future/x'], decoded_example['state/future/y'],\n",
        "      decoded_example['state/future/length'],\n",
        "      decoded_example['state/future/width'],\n",
        "      decoded_example['state/future/bbox_yaw'],\n",
        "      decoded_example['state/future/velocity_x'],\n",
        "      decoded_example['state/future/velocity_y']\n",
        "  ], -1)\n",
        "\n",
        "  gt_future_states = tf.concat([past_states, cur_states, future_states], 1)\n",
        "\n",
        "  past_is_valid = decoded_example['state/past/valid'] > 0\n",
        "  current_is_valid = decoded_example['state/current/valid'] > 0\n",
        "  future_is_valid = decoded_example['state/future/valid'] > 0\n",
        "  gt_future_is_valid = tf.concat(\n",
        "      [past_is_valid, current_is_valid, future_is_valid], 1)\n",
        "\n",
        "  # If a sample was not seen at all in the past, we declare the sample as\n",
        "  # invalid.\n",
        "  sample_is_valid = tf.reduce_any(\n",
        "      tf.concat([past_is_valid, current_is_valid], 1), 1)\n",
        "\n",
        "  inputs = {\n",
        "      'input_states': input_states,\n",
        "      'gt_future_states': gt_future_states,\n",
        "      'gt_future_is_valid': gt_future_is_valid,\n",
        "      'object_type': decoded_example['state/type'],\n",
        "      'tracks_to_predict': decoded_example['state/tracks_to_predict'] > 0,\n",
        "      'sample_is_valid': sample_is_valid,\n",
        "  }\n",
        "  return inputs\n",
        "\n",
        "\n",
        "def _default_metrics_config():\n",
        "  config = motion_metrics_pb2.MotionMetricsConfig()\n",
        "  config_text = \"\"\"\n",
        "  track_steps_per_second: 10\n",
        "  prediction_steps_per_second: 2\n",
        "  track_history_samples: 10\n",
        "  track_future_samples: 80\n",
        "  speed_lower_bound: 1.4\n",
        "  speed_upper_bound: 11.0\n",
        "  speed_scale_lower: 0.5\n",
        "  speed_scale_upper: 1.0\n",
        "  step_configurations {\n",
        "    measurement_step: 5\n",
        "    lateral_miss_threshold: 1.0\n",
        "    longitudinal_miss_threshold: 2.0\n",
        "  }\n",
        "  step_configurations {\n",
        "    measurement_step: 9\n",
        "    lateral_miss_threshold: 1.8\n",
        "    longitudinal_miss_threshold: 3.6\n",
        "  }\n",
        "  step_configurations {\n",
        "    measurement_step: 15\n",
        "    lateral_miss_threshold: 3.0\n",
        "    longitudinal_miss_threshold: 6.0\n",
        "  }\n",
        "  max_predictions: 6\n",
        "  \"\"\"\n",
        "  text_format.Parse(config_text, config)\n",
        "  return config\n",
        "\n",
        "\n",
        "class SimpleModel(tf.keras.Model):\n",
        "  \"\"\"A simple one-layer regressor.\"\"\"\n",
        "\n",
        "  def __init__(self, num_agents_per_scenario, num_states_steps,\n",
        "               num_future_steps):\n",
        "    super(SimpleModel, self).__init__()\n",
        "    self._num_agents_per_scenario = num_agents_per_scenario\n",
        "    self._num_states_steps = num_states_steps\n",
        "    self._num_future_steps = num_future_steps\n",
        "    self.regressor = tf.keras.layers.Dense(num_future_steps * 2)\n",
        "\n",
        "  def call(self, states):\n",
        "    states = tf.reshape(states, (-1, self._num_states_steps * 2))\n",
        "    pred = self.regressor(states)\n",
        "    pred = tf.reshape(\n",
        "        pred, [-1, self._num_agents_per_scenario, self._num_future_steps, 2])\n",
        "    return pred\n",
        "\n",
        "\n",
        "class MotionMetrics(tf.keras.metrics.Metric):\n",
        "  \"\"\"Wrapper for motion metrics computation.\"\"\"\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__()\n",
        "    self._prediction_trajectory = []\n",
        "    self._prediction_score = []\n",
        "    self._ground_truth_trajectory = []\n",
        "    self._ground_truth_is_valid = []\n",
        "    self._prediction_ground_truth_indices = []\n",
        "    self._prediction_ground_truth_indices_mask = []\n",
        "    self._object_type = []\n",
        "    self._metrics_config = config\n",
        "\n",
        "  def reset_state():\n",
        "    self._prediction_trajectory = []\n",
        "    self._prediction_score = []\n",
        "    self._ground_truth_trajectory = []\n",
        "    self._ground_truth_is_valid = []\n",
        "    self._prediction_ground_truth_indices = []\n",
        "    self._prediction_ground_truth_indices_mask = []\n",
        "    self._object_type = []\n",
        "\n",
        "  def update_state(self, prediction_trajectory, prediction_score,\n",
        "                   ground_truth_trajectory, ground_truth_is_valid,\n",
        "                   prediction_ground_truth_indices,\n",
        "                   prediction_ground_truth_indices_mask, object_type):\n",
        "    self._prediction_trajectory.append(prediction_trajectory)\n",
        "    self._prediction_score.append(prediction_score)\n",
        "    self._ground_truth_trajectory.append(ground_truth_trajectory)\n",
        "    self._ground_truth_is_valid.append(ground_truth_is_valid)\n",
        "    self._prediction_ground_truth_indices.append(\n",
        "        prediction_ground_truth_indices)\n",
        "    self._prediction_ground_truth_indices_mask.append(\n",
        "        prediction_ground_truth_indices_mask)\n",
        "    self._object_type.append(object_type)\n",
        "\n",
        "  def result(self):\n",
        "    # [batch_size, num_preds, 1, 1, steps, 2].\n",
        "    # The ones indicate top_k = 1, num_agents_per_joint_prediction = 1.\n",
        "    prediction_trajectory = tf.concat(self._prediction_trajectory, 0)\n",
        "    # [batch_size, num_preds, 1].\n",
        "    prediction_score = tf.concat(self._prediction_score, 0)\n",
        "    # [batch_size, num_agents, gt_steps, 7].\n",
        "    ground_truth_trajectory = tf.concat(self._ground_truth_trajectory, 0)\n",
        "    # [batch_size, num_agents, gt_steps].\n",
        "    ground_truth_is_valid = tf.concat(self._ground_truth_is_valid, 0)\n",
        "    # [batch_size, num_preds, 1].\n",
        "    prediction_ground_truth_indices = tf.concat(\n",
        "        self._prediction_ground_truth_indices, 0)\n",
        "    # [batch_size, num_preds, 1].\n",
        "    prediction_ground_truth_indices_mask = tf.concat(\n",
        "        self._prediction_ground_truth_indices_mask, 0)\n",
        "    # [batch_size, num_agents].\n",
        "    object_type = tf.cast(tf.concat(self._object_type, 0), tf.int64)\n",
        "\n",
        "    # We are predicting more steps than needed by the eval code. Subsample.\n",
        "    interval = (\n",
        "        self._metrics_config.track_steps_per_second //\n",
        "        self._metrics_config.prediction_steps_per_second)\n",
        "    prediction_trajectory = prediction_trajectory[...,\n",
        "                                                  (interval - 1)::interval, :]\n",
        "\n",
        "    return py_metrics_ops.motion_metrics(\n",
        "        config=self._metrics_config.SerializeToString(),\n",
        "        prediction_trajectory=prediction_trajectory,\n",
        "        prediction_score=prediction_score,\n",
        "        ground_truth_trajectory=ground_truth_trajectory,\n",
        "        ground_truth_is_valid=ground_truth_is_valid,\n",
        "        prediction_ground_truth_indices=prediction_ground_truth_indices,\n",
        "        prediction_ground_truth_indices_mask=prediction_ground_truth_indices_mask,\n",
        "        object_type=object_type)\n",
        "\n",
        "\n",
        "model = SimpleModel(128, 11, 80)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "metrics_config = _default_metrics_config()\n",
        "motion_metrics = MotionMetrics(metrics_config)\n",
        "metric_names = config_util.get_breakdown_names_from_motion_config(\n",
        "    metrics_config)\n",
        "\n",
        "\n",
        "def train_step(inputs):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # [batch_size, num_agents, D]\n",
        "    states = inputs['input_states']\n",
        "\n",
        "    # Predict. [batch_size, num_agents, steps, 2].\n",
        "    pred_trajectory = model(states, training=True)\n",
        "\n",
        "    # Set training target.\n",
        "    prediction_start = metrics_config.track_history_samples + 1\n",
        "\n",
        "    # [batch_size, num_agents, steps, 7]\n",
        "    gt_trajectory = inputs['gt_future_states']\n",
        "    gt_targets = gt_trajectory[..., prediction_start:, :2]\n",
        "\n",
        "    # [batch_size, num_agents, steps]\n",
        "    gt_is_valid = inputs['gt_future_is_valid']\n",
        "    # [batch_size, num_agents, steps]\n",
        "    weights = (\n",
        "        tf.cast(inputs['gt_future_is_valid'][..., prediction_start:],\n",
        "                tf.float32) *\n",
        "        tf.cast(inputs['tracks_to_predict'][..., tf.newaxis], tf.float32))\n",
        "\n",
        "    loss_value = loss_fn(gt_targets, pred_trajectory, sample_weight=weights)\n",
        "  grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "  # [batch_size, num_agents, steps, 2] ->\n",
        "  # [batch_size, num_agents, 1, 1, steps, 2].\n",
        "  # The added dimensions are top_k = 1, num_agents_per_joint_prediction = 1.\n",
        "  pred_trajectory = pred_trajectory[:, :, tf.newaxis, tf.newaxis]\n",
        "\n",
        "  # Fake the score since this model does not generate any score per predicted\n",
        "  # trajectory.\n",
        "  pred_score = tf.ones(shape=tf.shape(pred_trajectory)[:3])\n",
        "\n",
        "  # [batch_size, num_agents].\n",
        "  object_type = inputs['object_type']\n",
        "\n",
        "  # [batch_size, num_agents].\n",
        "  batch_size = tf.shape(inputs['tracks_to_predict'])[0]\n",
        "  num_samples = tf.shape(inputs['tracks_to_predict'])[1]\n",
        "\n",
        "  pred_gt_indices = tf.range(num_samples, dtype=tf.int64)\n",
        "  # [batch_size, num_agents, 1].\n",
        "  pred_gt_indices = tf.tile(pred_gt_indices[tf.newaxis, :, tf.newaxis],\n",
        "                            (batch_size, 1, 1))\n",
        "  # [batch_size, num_agents, 1].\n",
        "  pred_gt_indices_mask = inputs['tracks_to_predict'][..., tf.newaxis]\n",
        "\n",
        "  motion_metrics.update_state(pred_trajectory, pred_score, gt_trajectory,\n",
        "                              gt_is_valid, pred_gt_indices,\n",
        "                              pred_gt_indices_mask, object_type)\n",
        "\n",
        "  return loss_value\n",
        "\n",
        "\n",
        "dataset = tf.data.TFRecordDataset(FILENAME)\n",
        "dataset = dataset.map(_parse)\n",
        "dataset = dataset.batch(32)\n",
        "\n",
        "epochs = 2\n",
        "num_batches_per_epoch = 10\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print('\\nStart of epoch %d' % (epoch,))\n",
        "  start_time = time.time()\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, batch in enumerate(dataset):\n",
        "    loss_value = train_step(batch)\n",
        "\n",
        "    # Log every 10 batches.\n",
        "    if step % 10 == 0:\n",
        "      print('Training loss (for one batch) at step %d: %.4f' %\n",
        "            (step, float(loss_value)))\n",
        "      print('Seen so far: %d samples' % ((step + 1) * 64))\n",
        "\n",
        "    if step >= num_batches_per_epoch:\n",
        "      break\n",
        "\n",
        "  # Display metrics at the end of each epoch.\n",
        "  train_metric_values = motion_metrics.result()\n",
        "  for i, m in enumerate(\n",
        "      ['min_ade', 'min_fde', 'miss_rate', 'overlap_rate', 'map']):\n",
        "    for j, n in enumerate(metric_names):\n",
        "      print('{}/{}: {}'.format(m, n, train_metric_values[i, j]))"
      ],
      "metadata": {
        "id": "ye1Hc-Zl43OY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Access Google cloud storage "
      ],
      "metadata": {
        "id": "0gj8lTEfU9CC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a folder from google drive \n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abcWy2VJ4BVZ",
        "outputId": "987077f8-5122-4113-bee2-347e9c36c3ad"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save data to our own google cloud storage\n",
        "\n",
        "!gsutil -m cp -r \"gs://waymo_open_dataset_motion_v_1_2_0/uncompressed/tf_example\" \"gs://vt_stats_waymo_motion_open_data\""
      ],
      "metadata": {
        "id": "KApJwnY_uIzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, we need to authenticate and mount Google Drive in Colab\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/g')\n",
        "\n",
        "# Next, we need to install the Google Cloud Storage library\n",
        "!pip install google-cloud-storage\n",
        "\n",
        "# Then, we can create a client object to access our Google Cloud Storage data\n",
        "from google.cloud import storage\n",
        "client = storage.Client()"
      ],
      "metadata": {
        "id": "3MVaovoh60pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, we can access our data using the client object and the appropriate bucket and file paths\n",
        "bucket = client.get_bucket('vt_stats_waymo_motion_open_data')\n",
        "\n",
        "# Define the folder path where the TFRecords files are located\n",
        "folder_path = 'tf_example/validation_interactive/' # change to testing and validation\n",
        "\n",
        "# Get a list of all blobs in the folder with the given prefix\n",
        "blobs = bucket.list_blobs(prefix=folder_path)\n"
      ],
      "metadata": {
        "id": "MTRBasBm63v2"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a list of file paths for the TFRecords files\n",
        "file_paths = []\n",
        "for blob in blobs:\n",
        "    # if blob.name.endswith('.tfrecord'):\n",
        "    file_paths.append('gs://' + blob.bucket.name + '/' + blob.name)\n",
        "\n",
        "# Create a TFRecordDataset from the file paths\n",
        "# dataset = tf.data.TFRecordDataset(file_paths)"
      ],
      "metadata": {
        "id": "D1ymmyH80CCR"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "for i,f in enumerate(file_paths):\n",
        "  dataset = tf.data.TFRecordDataset(file_paths[i])\n",
        "  data = next(dataset.as_numpy_iterator())\n",
        "  parsed = tf.io.parse_single_example(data, features_description)\n",
        "\n",
        "\n",
        "# convert any non-serializable data types to a serializable data type\n",
        "  for key, value in parsed.items():\n",
        "      if isinstance(value, tf.Tensor):\n",
        "          parsed[key] = value.numpy().tolist()\n",
        "\n",
        "# dump the modified dictionary to a JSON file\n",
        "  with open('/content/drive/Shareddrives/Waymo Data Challenge/Rewrited data-Waymo Motion/tf_example_json/validation_interactive/'+ str(i) +'.json', 'w') as a:\n",
        "      json.dump(parsed, a)"
      ],
      "metadata": {
        "id": "ggEaPO4U0w_G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}